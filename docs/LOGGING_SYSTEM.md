# Sistema de Logs Estructurados - FreeSquash

## ğŸ“‹ DescripciÃ³n General

Este proyecto utiliza un sistema de logging estructurado basado en **Pino** que permite:

- âœ… **Logs en formato JSON** para anÃ¡lisis programÃ¡tico
- âœ… **RotaciÃ³n automÃ¡tica** de archivos de log
- âœ… **Contexto enriquecido** (userId, requestId, duraciÃ³n, etc.)
- âœ… **Herramientas de anÃ¡lisis** para extraer estadÃ­sticas
- âœ… **VisualizaciÃ³n** de mÃ©tricas y eventos

## ğŸ—ï¸ Arquitectura

### Estructura de Logs

Los logs se almacenan en formato JSON con la siguiente estructura:

```json
{
  "level": 30,
  "time": "2025-12-18T10:30:45.123Z",
  "app": "freesquash-api",
  "env": "production",
  "msg": "Match created successfully",
  "type": "business_event",
  "event": "match_created",
  "matchId": "abc123",
  "groupId": "def456",
  "userId": 42
}
```

### Niveles de Log

- `10` - **TRACE**: InformaciÃ³n muy detallada para debugging
- `20` - **DEBUG**: InformaciÃ³n de depuraciÃ³n
- `30` - **INFO**: InformaciÃ³n general (por defecto)
- `40` - **WARN**: Advertencias
- `50` - **ERROR**: Errores manejados
- `60` - **FATAL**: Errores crÃ­ticos que requieren atenciÃ³n inmediata

### Tipos de Logs

1. **business_event**: Eventos de negocio importantes
2. **http_request**: Peticiones HTTP
3. **error**: Errores y excepciones
4. **metric**: MÃ©tricas y estadÃ­sticas
5. **operation**: Operaciones con duraciÃ³n

## ğŸ”§ ConfiguraciÃ³n

### Variables de Entorno

```bash
# Nivel de logging (trace, debug, info, warn, error, fatal)
LOG_LEVEL=info

# Entorno
NODE_ENV=production
```

### Almacenamiento

Los logs se guardan en `apps/api/logs/`:

- `app.log` - Logs generales (rotaciÃ³n diaria, mantiene 30 dÃ­as)
- `error.log` - Solo errores (rotaciÃ³n diaria, mantiene 90 dÃ­as)
- `app.log.1.gz` - Archivos antiguos comprimidos

## ğŸ“ Uso en el CÃ³digo

### Logger BÃ¡sico

```typescript
import { logger } from './utils/logger';

// Log simple
logger.info('Server started successfully');

// Log con contexto
logger.info({ userId: 123, action: 'login' }, 'User logged in');

// Log de error
logger.error({ error, userId: 123 }, 'Failed to process request');
```

### Child Logger (Contexto Persistente)

```typescript
import { createChildLogger } from './utils/logger';

const requestLogger = createChildLogger({ 
  requestId: req.id, 
  userId: req.user.id 
});

requestLogger.info('Processing request');
requestLogger.info({ data: result }, 'Request completed');
```

### Helpers Especializados

#### Eventos de Negocio

```typescript
import { logBusinessEvent } from './utils/logger';

logBusinessEvent('match_created', {
  matchId: match.id,
  player1: 'John Doe',
  player2: 'Jane Smith',
  score: '3-1',
});
```

#### Operaciones con DuraciÃ³n

```typescript
import { logOperation } from './utils/logger';

const result = await logOperation(
  'calculate_rankings',
  async () => {
    // Tu cÃ³digo aquÃ­
    return await calculateGroupRankings(groupId);
  },
  { groupId }
);
// AutomÃ¡ticamente logea inicio, fin, duraciÃ³n y errores
```

#### Errores

```typescript
import { logError } from './utils/logger';

try {
  // cÃ³digo
} catch (error) {
  logError(error, { 
    operation: 'update_match',
    matchId: id 
  });
}
```

#### MÃ©tricas

```typescript
import { logMetric } from './utils/logger';

logMetric('active_users', 150, 'count', { 
  type: 'concurrent' 
});

logMetric('response_time', 245, 'ms', { 
  endpoint: '/api/matches' 
});
```

## ğŸ“Š AnÃ¡lisis de Logs

### Herramienta de AnÃ¡lisis

Incluye un script de anÃ¡lisis potente:

```bash
# Ver todos los comandos disponibles
tsx src/scripts/analyze-logs.ts

# EstadÃ­sticas de eventos de negocio
tsx src/scripts/analyze-logs.ts events

# AnÃ¡lisis de errores
tsx src/scripts/analyze-logs.ts errors

# MÃ©tricas de performance
tsx src/scripts/analyze-logs.ts performance

# Actividad por usuario
tsx src/scripts/analyze-logs.ts users

# Timeline de actividad
tsx src/scripts/analyze-logs.ts timeline

# Consultas personalizadas
tsx src/scripts/analyze-logs.ts query --type business_event --limit 50
tsx src/scripts/analyze-logs.ts query --level error --limit 100
```

### Ejemplos de Salida

#### Eventos de Negocio

```json
{
  "match_created": {
    "count": 145,
    "examples": [...]
  },
  "match_updated": {
    "count": 52,
    "examples": [...]
  },
  "server_started": {
    "count": 3,
    "examples": [...]
  }
}
```

#### AnÃ¡lisis de Errores

```json
{
  "ValidationError": {
    "count": 23,
    "lastSeen": "2025-12-18T14:30:00.000Z",
    "examples": [...]
  }
}
```

#### MÃ©tricas de Performance

```json
{
  "calculate_rankings": {
    "count": 145,
    "avg": 245,
    "min": 120,
    "max": 1200,
    "p50": 230,
    "p95": 450,
    "p99": 800
  }
}
```

## ğŸ” Consultas Avanzadas

### Usando jq (Linux/Mac/WSL)

```bash
# Contar eventos por tipo
cat logs/app.log | jq -r '.type' | sort | uniq -c

# Errores de las Ãºltimas 24 horas
cat logs/app.log | jq 'select(.level >= 50)'

# Top usuarios mÃ¡s activos
cat logs/app.log | jq 'select(.userId) | .userId' | sort | uniq -c | sort -rn

# DuraciÃ³n promedio por operaciÃ³n
cat logs/app.log | jq 'select(.duration) | [.operation, .duration]'

# Eventos de un usuario especÃ­fico
cat logs/app.log | jq 'select(.userId == 42)'
```

### ProgramÃ¡ticamente (Node.js)

```typescript
import { LogAnalyzer } from './scripts/analyze-logs';

const analyzer = new LogAnalyzer();

// Consulta personalizada
const results = await analyzer.query({
  level: 'error',
  startDate: '2025-12-01',
  endDate: '2025-12-18',
  userId: 42,
  limit: 100
});

// EstadÃ­sticas de eventos
const eventStats = await analyzer.businessEventStats();

// Performance de operaciones
const perfMetrics = await analyzer.performanceMetrics();
```

## ğŸ“ˆ Dashboard y VisualizaciÃ³n

### OpciÃ³n 1: Grafana + Loki (Recomendado para ProducciÃ³n)

1. Instalar Grafana Loki para agregaciÃ³n de logs
2. Configurar datasource apuntando a los archivos de log
3. Crear dashboards con:
   - GrÃ¡ficas de eventos por tiempo
   - Top errores
   - Performance de operaciones
   - Actividad de usuarios

### OpciÃ³n 2: ELK Stack (Elasticsearch, Logstash, Kibana)

1. Configurar Logstash para leer los logs JSON
2. Indexar en Elasticsearch
3. Crear visualizaciones en Kibana

### OpciÃ³n 3: AnÃ¡lisis Local con Scripts

Ver ejemplos de anÃ¡lisis con el script incluido arriba.

## ğŸ¯ Mejores PrÃ¡cticas

### 1. Logging Consistente

```typescript
// âœ… BIEN - Incluye contexto Ãºtil
logger.info({ 
  matchId, 
  userId, 
  duration: Date.now() - startTime 
}, 'Match updated successfully');

// âŒ MAL - Muy genÃ©rico
logger.info('Update complete');
```

### 2. No Loguear InformaciÃ³n Sensible

```typescript
// âœ… BIEN - Password redactado automÃ¡ticamente
logger.info({ email, role }, 'User created');

// âŒ MAL - Expone password
logger.info({ email, password, role }, 'User created');
```

### 3. Niveles Apropiados

```typescript
logger.trace('Entering function'); // Solo desarrollo
logger.debug('Variable value:', value); // Debugging
logger.info('User logged in'); // InformaciÃ³n general
logger.warn('Deprecated API used'); // Advertencias
logger.error({ error }, 'Failed to save'); // Errores
logger.fatal('Database connection lost'); // CrÃ­tico
```

### 4. Eventos de Negocio Significativos

Loguea eventos importantes del negocio:

- Usuario registrado/login
- Partido creado/actualizado/eliminado
- Cambios en rankings
- Promociones/descensos
- Errores de negocio (partidos duplicados, validaciones)

### 5. MÃ©tricas de Performance

Para operaciones importantes:

```typescript
const result = await logOperation('expensive_operation', 
  async () => {
    return await doSomethingExpensive();
  },
  { context: 'important' }
);
```

## ğŸ”’ Seguridad

Los siguientes campos se redactan automÃ¡ticamente:

- `password`
- `token`
- `accessToken`
- `req.headers.authorization`

## ğŸ“¦ RotaciÃ³n y Mantenimiento

- **Logs generales**: 30 dÃ­as
- **Logs de errores**: 90 dÃ­as
- **CompresiÃ³n**: Archivos antiguos se comprimen con gzip
- **RotaciÃ³n**: Diaria a medianoche

### Limpieza Manual

```bash
# Eliminar logs antiguos (Linux/Mac)
find logs/ -name "*.gz" -mtime +90 -delete

# Windows PowerShell
Get-ChildItem logs\*.gz | Where-Object {$_.LastWriteTime -lt (Get-Date).AddDays(-90)} | Remove-Item
```

## ğŸš€ PrÃ³ximas Mejoras

- [ ] Dashboard web integrado
- [ ] Alertas automÃ¡ticas por email/Slack
- [ ] ExportaciÃ³n a servicios cloud (CloudWatch, Datadog)
- [ ] AgregaciÃ³n de mÃ©tricas en tiempo real
- [ ] API REST para consultas de logs

## ğŸ“š Referencias

- [Pino Documentation](https://getpino.io/)
- [Fastify Logging](https://www.fastify.io/docs/latest/Reference/Logging/)
- [Best Practices for Structured Logging](https://www.loggly.com/ultimate-guide/node-logging-basics/)
